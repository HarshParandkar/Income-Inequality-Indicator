# -*- coding: utf-8 -*-
"""Income Inequality Indicator 2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wDqPLzSIMN8LoC3PET5Rh4Bwr6A57yRO
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer

from sklearn.preprocessing import LabelEncoder

from sklearn.preprocessing import StandardScaler

data=pd.read_excel("/content/dataset.xlsx")

data.shape

data.isnull().sum()
data.duplicated().sum()

data1 = data.filter(items=['area', 'subarea', 'country', 'region_wb', 'year', 'population', 'gdp', 'gini', 'ge1', 'a025', 'palma', 'middle50', 'ginia', 'sd', 'dy5', 'y50'])

data1.isnull().sum()

data1.info()

"""UNIVARIATE ANALYSIS"""

plt.figure(figsize=(10,6))
sns.histplot(data1['gdp'], kde=True)
plt.title("GDP Distribution")
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(data1['population'], kde=True)
plt.title("Population Distribution")
plt.show()

"""BIVARIATE ANALYSIS"""

plt.figure(figsize=(10,6))
sns.histplot(data1['gdp'], kde=True)
plt.title("GDP Distribution")
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(data1['population'], kde=True)
plt.title("Population Distribution")
plt.show()

"""**Multivariate Analysis**

Making the data fully numeric:
"""

encoder = LabelEncoder()
for col in ['area', 'subarea', 'country', 'region_wb']:
    data1[col] = encoder.fit_transform(data1[col])

non_numeric = data1.apply(lambda s: pd.to_numeric(s, errors='coerce').isnull().any())
print("Non-numeric columns:", data1.columns[non_numeric])

data1 = data1.apply(pd.to_numeric, errors='coerce')
data1.isnull().sum()

si_median = SimpleImputer(strategy='median')
data1['population'] = si_median.fit_transform(data1[['population']])
data1['gdp'] = si_median.fit_transform(data1[['gdp']])
data1['gini'] = si_median.fit_transform(data1[['gini']])

si_mean = SimpleImputer(strategy='mean')
for col in ['ge1', 'a025', 'palma', 'middle50', 'ginia', 'sd', 'dy5', 'y50']:
    data1[col] = si_mean.fit_transform(data1[[col]])

plt.figure(figsize=(10,10))
sns.heatmap(data1.corr(), annot=True, cmap='coolwarm', center=0)
plt.title("Correlation Matrix")
plt.show()

"""Handling Missing Values"""

from sklearn.impute import SimpleImputer
si_most_frequent = SimpleImputer(strategy='most_frequent')
data1['region_wb'] = si_most_frequent.fit_transform(data1[['region_wb']])

si_median = SimpleImputer(strategy='median')
data1['population'] = si_median.fit_transform(data1[['population']])
data1['gdp'] = si_median.fit_transform(data1[['gdp']])
data1['gini'] = si_median.fit_transform(data1[['gini']])

si_mean = SimpleImputer(strategy='mean')
for col in ['ge1', 'a025', 'palma', 'middle50', 'ginia', 'sd', 'dy5', 'y50']:
    data1[col] = si_mean.fit_transform(data1[[col]])

# Recheck missing values
data1.isnull().sum()

"""ENCODING CATEGORICAL VALUES"""

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
for col in ['area', 'subarea', 'country', 'region_wb']:
    data1[col] = encoder.fit_transform(data1[col])

"""Scaling Features"""

X = data1.drop('gini', axis=1)
y = data1[['gini']]


scaler = StandardScaler()

X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

"""TRAIN TEST SPLIT"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""# MODEL BUILDING AND EVALUATION"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Regression Models Function
def evaluate_model(model, x_train, y_train, x_test, y_test):
    model.fit(x_train, y_train)
    predictions = model.predict(x_test)
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    mae = mean_absolute_error(y_test, predictions)
    return mse, r2, mae

"""Linear Regression Model"""

lr = LinearRegression()
mse_lr, r2_lr, mae_lr = evaluate_model(lr, x_train, y_train, x_test, y_test)
print(f"Linear Regression -> MSE: {mse_lr}, R2: {r2_lr}, MAE: {mae_lr}")

"""Decision Tree Model"""

dt = DecisionTreeRegressor(random_state=42)
mse_dt, r2_dt, mae_dt = evaluate_model(dt, x_train, y_train, x_test, y_test)
print(f"Decision Tree Regression -> MSE: {mse_dt}, R2: {r2_dt}, MAE: {mae_dt}")

"""Random Forest Regression"""

rf = RandomForestRegressor(random_state=42)
mse_rf, r2_rf, mae_rf = evaluate_model(rf, x_train, y_train, x_test, y_test)
print(f"Random Forest Regression -> MSE: {mse_rf}, R2: {r2_rf}, MAE: {mae_rf}")

"""Polynomial Regression"""

poly = PolynomialFeatures(degree=2)
x_train_poly = poly.fit_transform(x_train)
x_test_poly = poly.transform(x_test)
mse_poly, r2_poly, mae_poly = evaluate_model(DecisionTreeRegressor(random_state=42), x_train_poly, y_train, x_test_poly, y_test)
print(f"Polynomial Regression -> MSE: {mse_poly}, R2: {r2_poly}, MAE: {mae_poly}")

"""## MODEL COMPARISION"""

print("\nModel Comparison:")
print(f"Linear Regression -> MSE: {mse_lr}, R2: {r2_lr}, MAE: {mae_lr}")
print(f"Decision Tree -> MSE: {mse_dt}, R2: {r2_dt}, MAE: {mae_dt}")
print(f"Random Forest -> MSE: {mse_rf}, R2: {r2_rf}, MAE: {mae_rf}")
print(f"Polynomial Regression -> MSE: {mse_poly}, R2: {r2_poly}, MAE: {mae_poly}")

"""# SAVING THE BEST MODEL

Random Forest was observed to be the best one
"""

import pickle
with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(rf, file)

from joblib import dump
dump(rf, 'random_forest_model.joblib')